import os, glob, numpy, time
os.chdir('/media/ykartal/depo/calismalar/bilgisayarla_goru/malwareClassification/CompVisionDataset/malimg_paper_dataset_imgs/input/')  # the parent folder with sub-folders

list_fams = os.listdir(os.getcwd())  # vector of strings with family names

no_imgs = []  # No. of samples per family

for i in range(len(list_fams)):
    os.chdir(list_fams[i])
    len1 = len(glob.glob('*.png'))  # assuming the images are stored as 'png'
    no_imgs.append(len1)
    os.chdir('..')

total = sum(no_imgs)  # total number of all samples
y = numpy.zeros(total)  # label vector

temp1 = numpy.zeros(len(no_imgs) + 1)
temp1[1:len(temp1)] = no_imgs
temp2 = int(temp1[0]);  # now temp2 is [0 no_imgs]

for jj in range(len(no_imgs)): 
    temp3 = temp2 + int(temp1[jj + 1])
    for ii in range(temp2, temp3): 
        y[ii] = jj
    temp2 = temp2 + int(temp1[jj + 1])

from PIL import Image
import leargist

 
X = numpy.zeros((sum(no_imgs),320)) # Feature Matrix
cnt = 0
for i in range(len(list_fams)):
    os.chdir(list_fams[i])
    img_list = glob.glob('*.png') # Getting only 'png' files in a folder
    for j in range(len(img_list)):
        im = Image.open(img_list[j])
        im1 = im.resize((64,64),Image.ANTIALIAS); # for faster computation
        des = leargist.color_gist(im1)
#         print(des.shape)
#         print(des.dtype)
#         print(des.shape)
#         print(des.shape)
#         print(des.shape)
        X[cnt] = des[:320]  #????????????????????????????
        cnt = cnt + 1 
    os.chdir('..')
os.chdir('../output') # some folder for storing
fname = 'malimg'; 
import cPickle
cPickle.dump(list_fams,open(fname+'.p','wb')) # 'fname' can be the name of the dataset
numpy.save(fname +'_features.npy',X)
numpy.save(fname+'_labels.npy',y)

import random
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import shuffle 

n_samples, n_features = X.shape 
p = range(n_samples) # an index array, 0:n_samples
random.seed(random.random()) 
random.shuffle(p) # the index array is now shuffled

X, y = X[p], y[p] # both the arrays are now shuffled

kfold = 10 # no. of folds (better to have this at the start of the code)

skf = StratifiedKFold(kfold)
skfNum = skf.get_n_splits(X, y)

# Stratified KFold: This first divides the data into k folds. Then it also makes sure that the distribution of the data in each fold follows the original input distribution 
# Note: in future versions of scikit.learn, this module will be fused with kfold

skfind = [None]*skfNum # indices
cnt=0
for train_index in skf.split(X, y):
    skfind[cnt] = train_index
    cnt = cnt + 1

# skfind[i][0] -> train indices, skfind[i][1] -> test indices

# Supervised Classification with k-fold Cross Validation

from sklearn.metrics import confusion_matrix
from sklearn.neighbors import KNeighborsClassifier

conf_mat = numpy.zeros((len(no_imgs),len(no_imgs))) # Initializing the Confusion Matrix

n_neighbors = 1; # better to have this at the start of the code

# 10-fold Cross Validation
from keras.models import Sequential
from keras.applications.vgg16 import VGG16
from keras.layers import Dense, InputLayer, Dropout
model = Sequential()
model.add(InputLayer((320,)))    # input layer
model.add(Dense(units=1024, activation='sigmoid')) # hidden layer
model.add(Dense(25, activation='sigmoid'))    # output layer
model.summary()
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

from sklearn.model_selection import train_test_split
from keras.utils import np_utils
dummy_y = np_utils.to_categorical(y)   
X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)    # preparing the validation set


# Training
tic = time.time()
model.fit(X_train,y_train, epochs=20, batch_size=10) 
toc = time.time()
print ("training time= ", toc-tic) # roughly 2.5 secs

# Testing
y_predict = []
tic = time.time()
y_predict = model.predict(X_valid) # output is labels and not indices
toc = time.time()
print ("testing time = ", toc-tic) # roughly 0.3 secs

# Compute confusion matrix
cm = []
cm = confusion_matrix(y_valid,y_predict)
conf_mat = conf_mat + cm 
 
conf_mat = conf_mat.T # since rows and  cols are interchanged
avg_acc = numpy.trace(conf_mat)/sum(no_imgs)
conf_mat_norm = conf_mat/no_imgs # Normalizing the confusion matrix


# Viewing the confusion matrix
import matplotlib.pyplot as plt
plt.imshow(conf_mat_norm, interpolation='nearest')
plt.title('Confusion matrix')
plt.colorbar()
plt.show()
plt.savefig('confusion_matrix.png')

conf_mat2 = numpy.around(conf_mat_norm,decimals=2) # rounding to display in figure
plt.imshow(conf_mat2,interpolation='nearest')
for x in xrange(len(list_fams)):
  for y in xrange(len(list_fams)):
    plt.annotate(str(conf_mat2[x][y]),xy=(y,x),ha='center',va='center')

plt.xticks(range(len(list_fams)),list_fams,rotation=90,fontsize=11)
plt.yticks(range(len(list_fams)),list_fams,fontsize=11)
plt.title('Confusion matrix')
plt.colorbar()
plt.show()
plt.savefig('confusion_matrix2.png')

